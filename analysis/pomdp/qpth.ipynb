{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import qpth\n",
    "import cvxpy as cp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal value is 1.875\n",
      "A solution x is\n",
      "[0.25 0.75]\n",
      "A dual solution corresponding to the inequality constraints is\n",
      "[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# from https://www.cvxpy.org/examples/basic/quadratic_program.html\n",
    "# arrays come from https://cvxopt.org/examples/tutorial/qp.html\n",
    "\n",
    "n = 2\n",
    "m = 2\n",
    "\n",
    "Q = 2*np.array([ [2, .5], [.5, 1] ])\n",
    "p = np.array([1.0, 1.0])\n",
    "\n",
    "G = np.array([[-1.0,0.0],[0.0,-1.0]])\n",
    "h = np.array([0.0,0.0])\n",
    "\n",
    "#A = np.array([1.0, 1.0], (1,2))\n",
    "A = np.array([1.0, 1.0]).reshape((1,2))\n",
    "b = np.array(1.0)\n",
    "\n",
    "# Define and solve the CVXPY problem.\n",
    "x = cp.Variable(n)\n",
    "prob = cp.Problem(cp.Minimize((1/2)*cp.quad_form(x, Q) + p.T@x),\n",
    "                 [G@x <= h,\n",
    "                  A@x == b])\n",
    "prob.solve()\n",
    "\n",
    "# Print result.\n",
    "print(\"\\nThe optimal value is\", prob.value)\n",
    "print(\"A solution x is\")\n",
    "print(x.value)\n",
    "print(\"A dual solution corresponding to the inequality constraints is\")\n",
    "print(prob.constraints[0].dual_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] tensor([[0.2500, 0.7500]])\n"
     ]
    }
   ],
   "source": [
    "res = qpth.qp.QPFunction(verbose=False)(*[\n",
    "    torch.tensor(v).float()\n",
    "    for v in [Q, p, G, h, A, b]\n",
    "])\n",
    "print(xsol, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function, Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class OptNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.A = Parameter(torch.rand((1,2)).double())\n",
    "        self.Q = Variable(2*torch.tensor([ [2, .5], [.5, 1] ]).double())\n",
    "        self.p = Variable(torch.tensor([1.0, 1.0]).double())\n",
    "        self.G = Variable(torch.tensor([[-1.0,0.0],[0.0,-1.0]]).double())\n",
    "        self.h = Variable(torch.tensor([0.0,0.0]).double())\n",
    "        self.b = Variable(torch.tensor(1.0).double())\n",
    "\n",
    "    def forward(self, data):\n",
    "        return qpth.qp.QPFunction(verbose=-1)(\n",
    "            self.Q, self.p, self.G, self.h, self.A, self.b\n",
    "        ).float()#.view_as(puzzles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2549, 1.1306]], grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = OptNet()\n",
    "model.forward(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial value Parameter containing:\n",
      "tensor([[0.8195, 0.4173]], dtype=torch.float64, requires_grad=True)\n",
      "Iteration 24, loss = 0.008166614919900894\n",
      "Iteration 49, loss = 0.0021558504085987806\n",
      "Iteration 74, loss = 0.00010271537030348554\n",
      "Iteration 99, loss = 2.5335580744467734e-07\n",
      "Iteration 124, loss = 2.3296068718536844e-07\n",
      "Iteration 149, loss = 3.812014881532377e-08\n",
      "Iteration 174, loss = 3.6944207693068165e-09\n",
      "Iteration 199, loss = 2.96603630545178e-10\n",
      "Fitted value Parameter containing:\n",
      "tensor([[1.0000, 1.0000]], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = OptNet()\n",
    "print('Initial value', model.A)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "learning_rate = 1e-1\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "progress = 25\n",
    "for t in range(200):\n",
    "    y_true = torch.tensor([0.25, 0.75]) # should be [1, 1]\n",
    "    #y_true = torch.tensor([[0.45454545, 0.31818182]]) # should be [1.5, 1]\n",
    "    y_pred = model(None)\n",
    "    loss = loss_fn(y_pred, y_true)\n",
    "    if (t+1)%progress == 0:\n",
    "        print('Iteration {}, loss = {}'.format(t, loss.item()))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print('Fitted value', model.A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
