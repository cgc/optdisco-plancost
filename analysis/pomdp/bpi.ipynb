{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pomdp\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[20.0000, 19.0000],\n",
      "        [19.0000, 20.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.8796, 10.1191],\n",
       "        [ 9.8667, 10.1315]])"
      ]
     },
     "execution_count": 762,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T, O, R = pomdp.env_simple(incorrect=0, coherence=1)\n",
    "simple_pomdp_policy = pomdp.env_simple_fsc()\n",
    "# some baselines... see what learning does?\n",
    "spa, sps = pomdp.fsc_to_stochastic(simple_pomdp_policy[0], simple_pomdp_policy[1], T)\n",
    "print(pomdp.policy_evaluation_sr(spa, sps, T, O, R, 0.95))\n",
    "spa, sps = pomdp.random_fsc(2, T, O, R)\n",
    "pomdp.policy_evaluation_sr(spa, sps, T, O, R, 0.95)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = torch.tensor([\n",
    "    # s = 0, a = 0,1,2\n",
    "    [\n",
    "        [0.5, 0.5],\n",
    "        [0.5, 0.5],\n",
    "        [1.0, 0.0],\n",
    "    ],\n",
    "    # s = 1, a = 0,1,2\n",
    "    [\n",
    "        [0.5, 0.5],\n",
    "        [0.5, 0.5],\n",
    "        [0.0, 1.0],\n",
    "    ]\n",
    "])\n",
    "\n",
    "p = 0.85\n",
    "O = torch.tensor([\n",
    "    # a = 0, s' = 0,1\n",
    "    [\n",
    "        [0.5, 0.5],\n",
    "        [0.5, 0.5],\n",
    "    ],\n",
    "    # a = 1, s' = 0,1\n",
    "    [\n",
    "        [0.5, 0.5],\n",
    "        [0.5, 0.5],\n",
    "    ],\n",
    "    # a = 2, s' = 0,1\n",
    "    [\n",
    "        [p, 1-p],\n",
    "        [1-p, p],\n",
    "    ]\n",
    "])\n",
    "\n",
    "R = torch.tensor([\n",
    "    # s = 0\n",
    "    [+10, -100, -1],\n",
    "    # s = 1\n",
    "    [-100, +10, -1],\n",
    "]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fsc_action = torch.tensor([2, 2, 0, 2, 1])\n",
    "opt_fsc_state = torch.tensor([\n",
    "    [1, 3],\n",
    "    [2, 0],\n",
    "    [0, 0],\n",
    "    [0, 4],\n",
    "    [0, 0],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tensors used as indices must be long, byte or bool tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-350-b2af29d9bc91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfsc_action\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             V[n, s] = R[s, a] + gamma * sum([\n\u001b[0m\u001b[1;32m     13\u001b[0m                 T[s, a, ns] * sum(\n\u001b[1;32m     14\u001b[0m                     \u001b[0mO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfsc_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tensors used as indices must be long, byte or bool tensors"
     ]
    }
   ],
   "source": [
    "gamma = 0.95\n",
    "\n",
    "num_nodes, num_states = len(fsc_action), T.shape[0]\n",
    "num_obs = O.shape[2]\n",
    "\n",
    "V = torch.zeros((num_nodes, num_states))\n",
    "for idx in range(200):\n",
    "    prev = torch.clone(V)\n",
    "    for n in range(num_nodes):\n",
    "        for s in range(num_states):\n",
    "            a = fsc_action[n]\n",
    "            V[n, s] = R[s, a] + gamma * sum([\n",
    "                T[s, a, ns] * sum(\n",
    "                    O[a, ns, o] * V[fsc_state[n, o], ns]\n",
    "                    for o in range(num_obs)\n",
    "                )\n",
    "                for ns in range(num_states)\n",
    "            ])\n",
    "    if torch.norm(prev-V) < 1e-5:\n",
    "        print('Converged', idx)\n",
    "        break\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged 108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 19.3677,  19.3677],\n",
       "        [ 24.6921,   3.0113],\n",
       "        [ 28.3993, -81.6007],\n",
       "        [  3.0113,  24.6921],\n",
       "        [-81.6007,  28.3993]])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def policy_evaluation(fsc_action, fsc_state, T, O, R, *, gamma=0.95, debug=True, max_iter=5000, vi_eps=1e-3):\n",
    "    num_nodes, num_states = len(fsc_action), T.shape[0]\n",
    "    num_obs = O.shape[2]\n",
    "\n",
    "    V = torch.zeros((num_nodes, num_states))\n",
    "    for idx in range(max_iter):\n",
    "        prev = torch.clone(V)\n",
    "        for n in range(num_nodes):\n",
    "            a = fsc_action[n]\n",
    "            state_vals = torch.sum(O[a] * V[fsc_state[n]].T, axis=1)\n",
    "            V[n] = R[:, a] + gamma * T[:, a] @ state_vals\n",
    "        '''\n",
    "        for n in range(num_nodes):\n",
    "            for s in range(num_states):\n",
    "                a = fsc_action[n]\n",
    "                nn = fsc_state[n]\n",
    "\n",
    "                state_vals = np.sum(O[a] * V[fsc_state[n]].T, axis=1)\n",
    "                V[n, s] = R[s, a] + gamma * T[s, a] @ state_vals\n",
    "        '''\n",
    "        if torch.norm(prev-V) < vi_eps:\n",
    "            if debug:\n",
    "                print('Converged', idx)\n",
    "            break\n",
    "    return V\n",
    "policy_evaluation(opt_fsc_action, opt_fsc_state, T, O, R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic controllers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 1., 0.]]), tensor([[[0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0.]],\n",
       " \n",
       "         [[0., 0., 1., 0., 0.],\n",
       "          [1., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[1., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1.]],\n",
       " \n",
       "         [[1., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0.]]]))"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def det_to_stoch(fsc_action, fsc_state, T):\n",
    "    num_states, num_actions, _ = T.shape\n",
    "    num_nodes, num_obs = fsc_state.shape\n",
    "    a = torch.zeros((num_nodes, num_actions))\n",
    "    s = torch.zeros((num_nodes, num_actions, num_obs, num_nodes))\n",
    "    for n in range(num_nodes):\n",
    "        a[n, fsc_action[n]] = 1.\n",
    "        for o in range(num_obs):\n",
    "            s[n, fsc_action[n], o, fsc_state[n, o]] = 1.\n",
    "    return a, s.sum(1)\n",
    "\n",
    "det_to_stoch(opt_fsc_action, opt_fsc_state, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2]) tensor([[ 19.3714,  19.3714],\n",
      "        [ 24.6957,   3.0148],\n",
      "        [ 28.4028, -81.5972],\n",
      "        [  3.0148,  24.6957],\n",
      "        [-81.5972,  28.4028]])\n",
      "torch.Size([5, 2]) tensor([[ 19.3714,  19.3714],\n",
      "        [ 24.6957,   3.0148],\n",
      "        [ 28.4028, -81.5972],\n",
      "        [  3.0148,  24.6957],\n",
      "        [-81.5972,  28.4028]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# http://www.ifaamas.org/Proceedings/aamas2015/aamas/p1249.pdf\n",
    "# https://arxiv.org/pdf/1301.6720.pdf\n",
    "def policy_evaluation_sr(fsc_action, fsc_state, T, O, R, *, gamma=0.95, dtype=torch.FloatTensor):\n",
    "    num_states, num_actions, _ = T.shape\n",
    "    num_nodes, num_obs = fsc_state.shape[0], O.shape[2]\n",
    "\n",
    "    fsc_action = fsc_action.type(dtype)\n",
    "    fsc_state = fsc_state.type(dtype)\n",
    "    T = T.type(dtype)\n",
    "    O = O.type(dtype)\n",
    "    R = R.type(dtype)\n",
    "        \n",
    "    '''\n",
    "    T # s, a, s' -> p(s'|s,a)\n",
    "    O # a, s', o -> p(o|a,s')\n",
    "    fsc_action # n,a -> p(a|n)\n",
    "    fsc_state # n, a, o, n' -> p(a,n'|n,o) OR n, o, n' -> p(n'|n,o)\n",
    "\n",
    "    p(n', s') = p(n'|s')p(s')\n",
    "    p(s', a) = p(s'|a)p(a)\n",
    "    p(n'|s') = \n",
    "\n",
    "    # given n,s\n",
    "    p(n', a, s') = p(n'|s',a) p(s',a)\n",
    "\n",
    "    p(a,s') = p(s'|a) p(a)\n",
    "\n",
    "    p(a) = p(a|n), from FSC\n",
    "    p(s'|a) = T(s, a, s') = p(s' | s, a), from transitions\n",
    "    p(n'|s', a) = p(n'|n, o) p(o|a,s')\n",
    "    \n",
    "    '''\n",
    "    if len(fsc_state.shape) == 4:\n",
    "        fsc_state = fsc_state.sum(axis=1) # marginalizing over actoin, makes it p(n'|,n,o)\n",
    "\n",
    "    assert torch.allclose(fsc_action.sum(-1), torch.ones(num_nodes).type(dtype))\n",
    "    assert torch.allclose(fsc_state.sum(-1), torch.ones((num_nodes, num_obs)).type(dtype))\n",
    "    assert torch.allclose(T.sum(-1), torch.ones((num_states, num_actions)).type(dtype))\n",
    "    assert torch.allclose(O.sum(-1), torch.ones((num_actions, num_states)).type(dtype))\n",
    "\n",
    "    # we want p(n',s'|n,s)\n",
    "    Tmu = torch.zeros((num_nodes, num_states, num_nodes, num_states)).type(dtype)\n",
    "    for n in range(num_nodes):\n",
    "        for s in range(num_states):\n",
    "            '''\n",
    "            ns = T[s].T @ fsc_action[n]\n",
    "            o = (O.T @ fsc_action[n]) @ ns\n",
    "            nn = fsc_state[n].T @ o\n",
    "            Tmu[n, s] = nn[:, None] * ns[None, :] # HACK HACK is this right?\n",
    "            '''\n",
    "            a_ns = T[s] * fsc_action[n, :, None]\n",
    "            assert torch.allclose(a_ns.sum(), torch.ones(1).type(dtype))\n",
    "            # (a, s', o) @ (o, n') = (a, s', n'), p(n'|a, s')\n",
    "            p_nn = O @ fsc_state[n]\n",
    "            assert torch.allclose(p_nn.sum(2), torch.ones(num_actions, num_states).type(dtype)), p_nn\n",
    "            Tmu[n, s] = (a_ns[:, :, None] * p_nn).sum(0).T\n",
    "            assert torch.allclose(Tmu[n, s].sum(), torch.ones(1).type(dtype))\n",
    "            # hack bad\n",
    "            #o = (O * a_ns[:, :, None]).sum((0, 1))\n",
    "            #print(o.shape, fsc_state[n].T.shape)\n",
    "            #nn = fsc_state[n].T @ o\n",
    "            #Tmu[n, s] = nn[:, None] * ns[None, :] # HACK HACK is this right?\n",
    "\n",
    "    # expected reward, (nodes, states)\n",
    "    Cmu = fsc_action@R.T\n",
    "\n",
    "    crossprod = num_nodes * num_states\n",
    "\n",
    "    sr = (torch.eye(crossprod).type(dtype) - gamma * Tmu.view((crossprod, crossprod))).inverse()\n",
    "    V = sr @ Cmu.view(crossprod)\n",
    "    return V.view((num_nodes, num_states))\n",
    "\n",
    "V = policy_evaluation_sr(*det_to_stoch(opt_fsc_action, opt_fsc_state, T) + (T, O, R))\n",
    "print(V.shape, V)\n",
    "V = policy_evaluation_sr(*det_to_stoch(opt_fsc_action, opt_fsc_state, T) + (T, O, R), dtype=torch.DoubleTensor)\n",
    "print(V.shape, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged 108\n",
      "torch.Size([5, 2]) tensor([[ 19.3677,  19.3677],\n",
      "        [ 24.6921,   3.0113],\n",
      "        [ 28.3993, -81.6007],\n",
      "        [  3.0113,  24.6921],\n",
      "        [-81.6007,  28.3993]])\n"
     ]
    }
   ],
   "source": [
    "def policy_evaluation_stoch(fsc_action, fsc_state, T, O, R, *, gamma=0.95, debug=True, max_iter=5000, vi_eps=1e-3):\n",
    "    num_states, num_actions, _ = T.shape\n",
    "    num_nodes, num_obs = fsc_state.shape[0], O.shape[2]\n",
    "\n",
    "    if len(fsc_state.shape) == 4:\n",
    "        fsc_state = fsc_state.sum(axis=1) # marginalizing over actoin, makes it p(n'|,n,o)\n",
    "\n",
    "    V = torch.zeros((num_nodes, num_states))\n",
    "    for idx in range(max_iter):\n",
    "        prev = torch.clone(V)\n",
    "        #'''\n",
    "        for n in range(num_nodes):\n",
    "            # (a, s')\n",
    "            val = torch.sum(\n",
    "                # This was computing when we were marginalizing out actions in this step\n",
    "                # (a, s', o) * (a, None, o, n') = (a, s', o, n') -(sum(ax=2))> (a, s', n')\n",
    "                #(O[:, :, :, None] * fsc_state[n, :, None]).sum(axis=2) *\n",
    "\n",
    "                # (a, s', o) @ (o, n') = (a, s', n')\n",
    "                O @ fsc_state[n] *\n",
    "                V.T[None, :, :], axis=2)\n",
    "            # (s, a) expected future value for state/action\n",
    "            Q = torch.sum(T * val[None, :, :], axis=2)\n",
    "            V[n] = (R + gamma * Q) @ fsc_action[n] # HAKKK \n",
    "            #V[n] = R @ fsc_action[n] + gamma * Q.sum(1) # HAKKK  # HAKKK  # HAKKK \n",
    "        #'''\n",
    "        '''\n",
    "        for n in range(num_nodes):\n",
    "            # (a, s')\n",
    "            val = torch.sum(\n",
    "                # (a, s', o) @ (o, n') = (a, s', n')\n",
    "                O @ fsc_state[n] *\n",
    "                V.T[None, :, :], axis=2)\n",
    "            # (s, a) expected future value for state/action\n",
    "            Q = torch.sum(T * val[None, :, :], axis=2)\n",
    "            V[n] = (R + gamma * Q) @ fsc_action[n]\n",
    "        '''\n",
    "        '''\n",
    "        np = torch\n",
    "        for n in range(num_nodes):\n",
    "            # (a, s')\n",
    "            val = np.sum(\n",
    "                # (a, s', o) @ (o, n') = (a, s', n')\n",
    "                O @ fsc_state[n] *\n",
    "                V.T[None, :, :], axis=2)\n",
    "            # (s, a) expected future value for state/action\n",
    "            Q = np.sum(T * val[None, :, :], axis=2)\n",
    "            V[n] = (R + gamma * Q) @ fsc_action[n]\n",
    "        '''\n",
    "        '''\n",
    "        np = torch\n",
    "        for n in range(num_nodes):\n",
    "            for s in range(num_states):\n",
    "                # (a, s')\n",
    "                val = np.sum(\n",
    "                    # (a, s', o) @ (o, n') = (a, s', n')\n",
    "                    O @ fsc_state[n] *\n",
    "                    V.T[None, :, :], axis=2)\n",
    "                # (a) expected future value for actions\n",
    "                val = np.sum(T[s] * val, axis=1)\n",
    "                V[n, s] = fsc_action[n] @ (R[s] + gamma * val)\n",
    "        '''\n",
    "        '''\n",
    "        for n in range(num_nodes):\n",
    "            for s in range(num_states):\n",
    "                V[n, s] = sum(\n",
    "                    fsc_action[n, a] * (\n",
    "                        R[s, a] + gamma * sum([\n",
    "                            T[s, a, ns] * O[a, ns, :] @ fsc_state[n, :, :] @ V[:, ns]\n",
    "                            for ns in range(num_states)\n",
    "                        ])\n",
    "                    )\n",
    "                    for a in range(num_actions))\n",
    "        '''\n",
    "        '''\n",
    "        for n in range(num_nodes):\n",
    "            for s in range(num_states):\n",
    "                V[n, s] = sum(fsc_action[n, a] * (R[s, a] + gamma * sum([\n",
    "                    T[s, a, ns] * sum(\n",
    "                        O[a, ns, o] * sum(fsc_state[n, o, nn] * V[nn, ns] for nn in range(num_nodes))\n",
    "                        for o in range(num_obs)\n",
    "                    )\n",
    "                    for ns in range(num_states)\n",
    "                ])) for a in range(num_actions))\n",
    "        '''\n",
    "        '''\n",
    "        # deterministic\n",
    "        for n in range(num_nodes):\n",
    "            a = fsc_action[n]\n",
    "            state_vals = np.sum(O[a] * V[fsc_state[n]].T, axis=1)\n",
    "            V[n] = R[:, a] + gamma * T[:, a] @ state_vals\n",
    "        '''\n",
    "        '''\n",
    "        for n in range(num_nodes):\n",
    "            for s in range(num_states):\n",
    "                a = fsc_action[n]\n",
    "                nn = fsc_state[n]\n",
    "\n",
    "                state_vals = np.sum(O[a] * V[fsc_state[n]].T, axis=1)\n",
    "                V[n, s] = R[s, a] + gamma * T[s, a] @ state_vals\n",
    "        '''\n",
    "        if torch.norm(prev-V) < vi_eps:\n",
    "            if debug:\n",
    "                print('Converged', idx)\n",
    "            break\n",
    "    return V\n",
    "\n",
    "# TODO, make SR !@ TODO TODO\n",
    "V = policy_evaluation_stoch(*det_to_stoch(opt_fsc_action, opt_fsc_state, T) + (T, O, R))\n",
    "print(V.shape, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged 158\n",
      "tensor([[-597.9113, -579.3220],\n",
      "        [-582.1718, -600.5173],\n",
      "        [-601.5294, -574.9779],\n",
      "        [-572.0983, -594.1543],\n",
      "        [-580.1440, -605.3372],\n",
      "        [-588.0622, -585.0547],\n",
      "        [-583.5579, -588.9789]])\n",
      "Converged 160\n",
      "tensor([[-597.9112, -579.3219],\n",
      "        [-582.1716, -600.5172],\n",
      "        [-601.5293, -574.9778],\n",
      "        [-572.0982, -594.1542],\n",
      "        [-580.1439, -605.3372],\n",
      "        [-588.0621, -585.0546],\n",
      "        [-583.5577, -588.9788]])\n",
      "tensor([[-597.9116, -579.3223],\n",
      "        [-582.1720, -600.5177],\n",
      "        [-601.5297, -574.9782],\n",
      "        [-572.0986, -594.1545],\n",
      "        [-580.1443, -605.3375],\n",
      "        [-588.0625, -585.0551],\n",
      "        [-583.5581, -588.9792]])\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "T, O, R = pomdp.tiger()\n",
    "fsc_action, fsc_state = random_fsc(7, T, O, R, action_condition=True)\n",
    "print(pomdp.policy_evaluation_stoch_old(fsc_action, fsc_state, T, O, R, 0.95, vi_eps=1e-10))\n",
    "print(pomdp.policy_evaluation_stoch(fsc_action, fsc_state, T, O, R, 0.95, vi_eps=1e-10))\n",
    "print(pomdp.policy_evaluation_sr(fsc_action, fsc_state, T, O, R, 0.95))\n",
    "'''\n",
    "exact, for action_condition=True\n",
    "\n",
    "exact, for action_condition=False\n",
    "tensor([[-604.2139, -582.0386],\n",
    "        [-587.4158, -603.8062],\n",
    "        [-607.6362, -578.1958],\n",
    "        [-578.3529, -596.7704]])\n",
    "\n",
    "tensor([[-604.2104, -582.0352],\n",
    "        [-587.4125, -603.8028],\n",
    "        [-607.6329, -578.1927],\n",
    "        [-578.3497, -596.7672]])\n",
    "'''\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to write the constraint out...\n",
    "#ret = (T * (O * (canz@V).transpose(1, 2)).sum(2)[None, :, :]).sum(axis=(1, 2))\n",
    "#R@c_a + gamma * ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Double but got scalar type Float for sequence element 1 in sequence argument at position #1 'tensors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-789-884a47892079>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_constraints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;31m#A, b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-789-884a47892079>\u001b[0m in \u001b[0;36mmake_constraints\u001b[0;34m(n, V, T, O, R)\u001b[0m\n\u001b[1;32m     15\u001b[0m     h = torch.cat((\n\u001b[1;32m     16\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_actions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcanz_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     ))\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Double but got scalar type Float for sequence element 1 in sequence argument at position #1 'tensors'"
     ]
    }
   ],
   "source": [
    "def make_constraints(n, V, T, O, R):\n",
    "    num_states, num_actions, _ = T.shape\n",
    "    num_nodes = V.shape[0]\n",
    "    num_obs = O.shape[2]\n",
    "\n",
    "    canz_shape = torch.Size((num_actions, num_obs, num_nodes))\n",
    "\n",
    "    args = 1 + num_actions + canz_shape.numel()\n",
    "\n",
    "    delta_slice = slice(0, 1)\n",
    "    c_a_slice = slice(1, 1 + num_actions)\n",
    "    canz_slice = slice(1 + num_actions, None)\n",
    "\n",
    "    G = torch.zeros((V.shape[1] + num_actions + canz_shape.numel(), args))\n",
    "    h = torch.cat((\n",
    "        -V[n],\n",
    "        torch.zeros(num_actions + canz_shape.numel()),\n",
    "    ))\n",
    "\n",
    "    # Last spots encode c >= 0 as -c <= 0\n",
    "    for idx in range(num_actions + canz_shape.numel()):\n",
    "        G[num_states+idx, delta_slice.stop+idx] = -1\n",
    "\n",
    "    for s in range(num_states):\n",
    "        G[s, delta_slice] = 1\n",
    "        G[s, c_a_slice] = -R[s]\n",
    "        canz_coef = G[s, canz_slice].view(canz_shape)\n",
    "\n",
    "        # (a, s', o)\n",
    "        #xx = T[s, :, :, None]*O\n",
    "        for a in range(num_actions):\n",
    "            for o in range(num_obs):\n",
    "                for nn in range(num_nodes):\n",
    "                    #c_a,n_z = p(n_z|a,n) p(a|n)\n",
    "                    #p(n_z|a,n) = p(n_z|a) = p(n_z|o) p(o|a)\n",
    "                    #p(o|a) xxxx\n",
    "                    canz_coef[a, o, nn] = -gamma * (T[s, a, :] * O[a, :, o] * V[nn]).sum()\n",
    "\n",
    "    # Q has to be PSD... so I've scaled it down considerably here\n",
    "    Q = torch.eye(args) * 1e-4\n",
    "    p = torch.zeros(args)\n",
    "    # The default optimization is an argmin, so this lets us maximize the delta!\n",
    "    p[delta_slice] = -1\n",
    "\n",
    "    # HACK HACK in the future, write these so we don't need c_a?? to be simpler??\n",
    "    A = torch.zeros((num_actions+1, args))\n",
    "    b = torch.zeros(A.shape[0])\n",
    "\n",
    "    # \\sum_a c_a = 1\n",
    "    A[num_actions, c_a_slice] = 1\n",
    "    b[num_actions] = 1\n",
    "\n",
    "    # for each a, \\sum_a c_a_n_z = c_a\n",
    "    for a in range(num_actions):\n",
    "        A[a, c_a_slice][a] = -1\n",
    "        A[a, canz_slice].view(canz_shape)[a] = 1\n",
    "\n",
    "    return Q, p, G, h, A, b\n",
    "\n",
    "Q, p, G, h, A, b = make_constraints(0, V, T, O, R)\n",
    "#A, b\n",
    "G[2], h[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qpth\n",
    "constraints = make_constraints(0, V, T, O, R)\n",
    "soln = qpth.qp.QPFunction(verbose=-1)(*constraints).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan)"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soln.flatten()[canz_slice].view(canz_shape).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[3, 2, 3]' is invalid for input of size 30",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-389-d1fb9df172d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msoln\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdelta_slice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msoln\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc_a_slice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msoln\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcanz_slice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanz_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m ]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[3, 2, 3]' is invalid for input of size 30"
     ]
    }
   ],
   "source": [
    "[\n",
    "    soln.flatten()[delta_slice],\n",
    "    soln.flatten()[c_a_slice],\n",
    "    soln.flatten()[canz_slice].view(canz_shape),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.3333, 0.3333, 0.3333]), tensor([[[0.1250, 0.1250, 0.1250],\n",
       "          [0.1250, 0.1250, 0.1250]],\n",
       " \n",
       "         [[0.1250, 0.1250, 0.1250],\n",
       "          [0.1250, 0.1250, 0.1250]],\n",
       " \n",
       "         [[0.1250, 0.1250, 0.1250],\n",
       "          [0.1250, 0.1250, 0.1250]]]), tensor(-9.8944))"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsc_action[n], fsc_state[n], soln.flatten()[canz_slice].view(canz.shape)[0, 1].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to fit..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 -14.195177063973624\n",
      "49 -15.048375633298345\n",
      "74 -15.10550803890106\n",
      "99 -15.127054119649422\n",
      "124 -15.14114085893618\n",
      "149 -15.151401423107314\n",
      "174 -15.159131071502808\n",
      "199 -15.165094320747649\n",
      "action, obs, node\n",
      "node 0 action p(a=0) 1.0\n",
      "p(n=0|o=0) 0.999\n",
      "p(n=1|o=1) 0.998\n",
      "node 1 action p(a=1) 1.0\n",
      "p(n=0|o=0) 0.999\n",
      "p(n=1|o=1) 0.999\n"
     ]
    }
   ],
   "source": [
    "# grad works...\n",
    "env = pomdp.env_simple(incorrect=0, coherence=1) # very simple\n",
    "env = pomdp.env_simple()\n",
    "d = pomdp.policy_iteration_grad(env, 0.95, grad_steps=200, progress=25)\n",
    "log_fsc(d['fsc_action'], d['fsc_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action, obs, node\n",
      "node 0 action p(a=0) 1.0\n",
      "p(n=1|a=0,o=0) 1.0\n",
      "p(n=0|a=0,o=1) 0.49\n",
      "p(n=1|a=0,o=1) 0.51\n",
      "p(n=0|a=1,o=0) 0.657\n",
      "p(n=1|a=1,o=0) 0.343\n",
      "p(n=0|a=1,o=1) 0.502\n",
      "p(n=1|a=1,o=1) 0.498\n",
      "node 1 action p(a=0) 0.85, p(a=1) 0.15\n",
      "p(n=0|a=0,o=0) 1.0\n",
      "p(n=0|a=0,o=1) 0.488\n",
      "p(n=1|a=0,o=1) 0.512\n",
      "p(n=0|a=1,o=0) 1.0\n",
      "p(n=0|a=1,o=1) 0.487\n",
      "p(n=1|a=1,o=1) 0.513\n"
     ]
    }
   ],
   "source": [
    "def log_fsc(fsc_action, fsc_state):\n",
    "    print('action, obs, node')\n",
    "    prev = -1\n",
    "    for idx in zip(*[x.detach().numpy() for x in torch.where(fsc_state>.01)]):\n",
    "        if prev != idx[0]:\n",
    "            print('node', idx[0], 'action', ', '.join([\n",
    "                f'p(a={i}) {round(p, 3)}'\n",
    "                for i, p in enumerate(fsc_action[idx[0]].detach().numpy())\n",
    "                if p > 1e-2]))\n",
    "        if len(idx) == 3:\n",
    "            o, n = idx[1:]\n",
    "            msg = f'p(n={n}|o={o})'\n",
    "        else:\n",
    "            a, o, n = idx[1:]\n",
    "            msg = f'p(n={n}|a={a},o={o})'\n",
    "        print(msg, round(fsc_state[idx].item(), 3))\n",
    "        prev = idx[0]\n",
    "log_fsc(fsc_action, fsc_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q tensor([[1.0000e-10, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e-10, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0000e-10, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e-10, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e-10, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e-10,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e-10, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0000e-10, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e-10]], dtype=torch.float64)\n",
      "p tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.], dtype=torch.float64)\n",
      "\n",
      "G tensor([[-9.5555, -9.6971, -1.9764, -1.9597, -8.5555, -8.6971, -0.9764, -0.9597,\n",
      "          1.0000],\n",
      "        [-0.9506, -0.9663, -8.7878, -8.6370, -1.9506, -1.9663, -9.7878, -9.6370,\n",
      "          1.0000],\n",
      "        [-1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000, -1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000, -1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000, -1.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000, -1.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -1.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -1.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -1.0000,\n",
      "          0.0000]], dtype=torch.float64)\n",
      "h tensor([-10.1721, -10.1018,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000], dtype=torch.float64)\n",
      "\n",
      "A tensor([[1., 1., 1., 1., 1., 1., 1., 1., 0.]], dtype=torch.float64)\n",
      "b tensor([1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "Q, p, G, h, A, b = pomdp.make_constraints_simple(n, V, T, O, R, gamma, dtype=dtype, qcoef=1e-10)[0]\n",
    "print('Q', Q)\n",
    "print('p', p)\n",
    "\n",
    "print()\n",
    "print('G', G)\n",
    "print('h', h)\n",
    "\n",
    "print()\n",
    "print('A', A)\n",
    "print('b', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value tensor([[10.0065, 10.2781],\n",
      "        [10.1721, 10.1018]], dtype=torch.float64)\n",
      "iter: 0, pri_resid: 4.75180e+00, dual_resid: 3.86813e+01, mu: 1.69933e+00\n",
      "iter: 1, pri_resid: 6.96482e-04, dual_resid: 5.80889e-15, mu: 1.38590e-01\n",
      "iter: 2, pri_resid: 9.71255e-05, dual_resid: 2.36667e-15, mu: 6.13253e-03\n",
      "iter: 3, pri_resid: 3.58792e-05, dual_resid: 2.35136e-15, mu: 3.66549e-03\n",
      "iter: 4, pri_resid: 1.55608e-06, dual_resid: 2.04473e-15, mu: 7.74429e-05\n",
      "iter: 5, pri_resid: 2.37925e-08, dual_resid: 1.39287e-15, mu: 8.64712e-08\n",
      "iter: 6, pri_resid: 3.73501e-11, dual_resid: 1.28826e-15, mu: 8.64712e-11\n",
      "iter: 7, pri_resid: 6.16878e-14, dual_resid: 1.72283e-15, mu: 8.64712e-14\n",
      "node 0 V delta -4.781377792358398\n",
      "node 0 V delta -4.781377792358398\n",
      "sums tensor(1.) tensor(1.) c_a tensor([1.0000e+00, 2.4968e-11])\n",
      "value tensor([[10.0065, 10.2781],\n",
      "        [10.1721, 10.1018]], dtype=torch.float64)\n",
      "iter: 0, pri_resid: 4.75396e+00, dual_resid: 3.85364e+01, mu: 1.69356e+00\n",
      "iter: 1, pri_resid: 8.43227e-04, dual_resid: 5.59128e-15, mu: 1.38161e-01\n",
      "iter: 2, pri_resid: 1.72416e-04, dual_resid: 2.29547e-15, mu: 6.11765e-03\n",
      "iter: 3, pri_resid: 6.45352e-05, dual_resid: 1.77171e-15, mu: 3.63877e-03\n",
      "iter: 4, pri_resid: 4.39531e-06, dual_resid: 2.21979e-15, mu: 6.57810e-05\n",
      "iter: 5, pri_resid: 3.22910e-08, dual_resid: 1.83883e-15, mu: 7.16567e-08\n",
      "iter: 6, pri_resid: 6.30095e-11, dual_resid: 2.00245e-15, mu: 7.16567e-11\n",
      "iter: 7, pri_resid: 9.89750e-14, dual_resid: 2.19116e-15, mu: 7.16567e-14\n",
      "node 1 V delta -4.777146339416504\n",
      "node 1 V delta -4.777146339416504\n",
      "sums tensor(1.) tensor(1.) c_a tensor([1.0000e+00, 2.1667e-11])\n",
      "0 tensor([[10.0065, 10.2781],\n",
      "        [10.1721, 10.1018]], dtype=torch.float64) tensor(0., dtype=torch.float64)\n",
      "converged!\n",
      "value tensor([[10.0065, 10.2781],\n",
      "        [10.1721, 10.1018]], dtype=torch.float64)\n",
      "iter: 0, pri_resid: 4.75180e+00, dual_resid: 3.86813e+01, mu: 1.69933e+00\n",
      "iter: 1, pri_resid: 6.96482e-04, dual_resid: 5.80889e-15, mu: 1.38590e-01\n",
      "iter: 2, pri_resid: 9.71255e-05, dual_resid: 2.36667e-15, mu: 6.13253e-03\n",
      "iter: 3, pri_resid: 3.58792e-05, dual_resid: 2.35136e-15, mu: 3.66549e-03\n",
      "iter: 4, pri_resid: 1.55608e-06, dual_resid: 2.04473e-15, mu: 7.74429e-05\n",
      "iter: 5, pri_resid: 2.37925e-08, dual_resid: 1.39287e-15, mu: 8.64712e-08\n",
      "iter: 6, pri_resid: 3.73501e-11, dual_resid: 1.28826e-15, mu: 8.64712e-11\n",
      "iter: 7, pri_resid: 6.16878e-14, dual_resid: 1.72283e-15, mu: 8.64712e-14\n",
      "node 0 V delta -4.781377792358398\n",
      "node 0 V delta -4.781377792358398\n",
      "sums tensor(1.) tensor(1.) c_a tensor([1.0000e+00, 2.4968e-11])\n",
      "value tensor([[10.0065, 10.2781],\n",
      "        [10.1721, 10.1018]], dtype=torch.float64)\n",
      "iter: 0, pri_resid: 4.75396e+00, dual_resid: 3.85364e+01, mu: 1.69356e+00\n",
      "iter: 1, pri_resid: 8.43227e-04, dual_resid: 5.59128e-15, mu: 1.38161e-01\n",
      "iter: 2, pri_resid: 1.72416e-04, dual_resid: 2.29547e-15, mu: 6.11765e-03\n",
      "iter: 3, pri_resid: 6.45352e-05, dual_resid: 1.77171e-15, mu: 3.63877e-03\n",
      "iter: 4, pri_resid: 4.39531e-06, dual_resid: 2.21979e-15, mu: 6.57810e-05\n",
      "iter: 5, pri_resid: 3.22910e-08, dual_resid: 1.83883e-15, mu: 7.16567e-08\n",
      "iter: 6, pri_resid: 6.30095e-11, dual_resid: 2.00245e-15, mu: 7.16567e-11\n",
      "iter: 7, pri_resid: 9.89750e-14, dual_resid: 2.19116e-15, mu: 7.16567e-14\n",
      "node 1 V delta -4.777146339416504\n",
      "node 1 V delta -4.777146339416504\n",
      "sums tensor(1.) tensor(1.) c_a tensor([1.0000e+00, 2.1667e-11])\n",
      "1 tensor([[10.0065, 10.2781],\n",
      "        [10.1721, 10.1018]], dtype=torch.float64) tensor(0., dtype=torch.float64)\n",
      "converged!\n"
     ]
    }
   ],
   "source": [
    "import pomdp\n",
    "T, O, R = pomdp.env_simple(incorrect=0, coherence=1)\n",
    "\n",
    "num_states, num_actions, _ = T.shape\n",
    "num_obs = O.shape[2]\n",
    "\n",
    "# canz -> p(n' | n, a, o) -> p(n', a, o | n) ??\n",
    "# c_a -> p(a | n)\n",
    "num_nodes = 5\n",
    "fsc_action = torch.ones((num_nodes, num_actions))/num_actions\n",
    "#fsc_state = torch.ones((num_nodes, num_actions, num_obs, num_nodes))/(num_actions+num_obs+num_nodes)\n",
    "#fsc_state = torch.ones((num_nodes, num_obs, num_nodes))/(num_nodes)\n",
    "fsc_state = torch.ones((num_nodes, num_actions, num_obs, num_nodes))/(num_actions+num_obs+num_nodes)\n",
    "\n",
    "num_nodes = 2\n",
    "\n",
    "fsc_action, fsc_state = pomdp.random_fsc(num_nodes, T, O, R, dtype=dtype, action_condition=True)\n",
    "#fsc_action, fsc_state = det_to_stoch(opt_fsc_action, opt_fsc_state, T)\n",
    "\n",
    "#fsc_action = torch.tensor(np.random.uniform(0, 1, size=(num_nodes, num_actions))).softmax(1).float()\n",
    "#xrnd = np.random.uniform(0, 1, size=(num_nodes, num_actions, num_obs, num_nodes))\n",
    "#fsc_state = torch.tensor(xrnd/np.sum(xrnd, axis=(1, 2, 3))).float()\n",
    "\n",
    "canz_shape = torch.Size((num_actions, num_obs, num_nodes))\n",
    "\n",
    "debug=True\n",
    "\n",
    "gamma = 0.95\n",
    "dtype = torch.float64\n",
    "steps = 2\n",
    "\n",
    "V = pomdp.policy_evaluation_sr(fsc_action, fsc_state, T, O, R, gamma, dtype=dtype)\n",
    "#V = pomdp.policy_evaluation_stoch(fsc_action, fsc_state, T, O, R, debug=False)\n",
    "for i in range(steps):\n",
    "    prev = V.clone()\n",
    "    for n in range(num_nodes):\n",
    "        V = pomdp.policy_evaluation_sr(fsc_action, fsc_state, T, O, R, gamma, dtype=dtype)\n",
    "        if debug:\n",
    "            print('value', V)\n",
    "        #V = policy_evaluation_stoch(fsc_action, fsc_state, T, O, R, debug=False)\n",
    "        constraints, unpack = pomdp.make_constraints_simple(n, V, T, O, R, gamma, dtype=dtype, qcoef=1e-10)\n",
    "        #soln = qpth.qp.QPFunction(verbose=True, solver=qpth.qp.QPSolvers.CVXPY)(*constraints).float()\n",
    "        soln = qpth.qp.QPFunction(verbose=debug)(*constraints).float()\n",
    "        #delta = soln[0, 0].item()\n",
    "        delta, c_a, canz = unpack(soln[0])\n",
    "        print('node', n, 'V delta', delta)\n",
    "        if debug:\n",
    "            print('node', n, 'V delta', delta)\n",
    "            print('sums', c_a.sum(), canz.sum(), 'c_a', c_a)\n",
    "        if delta > 0: # HACK check tos ee if xxx\n",
    "            #fsc_action[n] = soln[0, c_a_slice]\n",
    "            #fsc_action[n] = c_a\n",
    "            # normalize!!??\n",
    "            #fsc_action[n] = fsc_action[n] / fsc_action[n].sum()\n",
    "            #do we marginalize over actions?\n",
    "            # do we normalize so this is P(n'|n,o,a), instead of p(a,n'|n,o)?\n",
    "            #canz = soln[0, canz_slice].view(canz_shape)\n",
    "            # normalizing by p(a|n) to give us p(n'|n,o)\n",
    "            #fsc_state[n] = canz/canz.sum(0)\n",
    "            # HACK actually let's marginalize over actions first then normalize\n",
    "            # HACK actually we need to change this per the later meuleau\n",
    "            #canz = canz.sum(0)\n",
    "            #print(canz, canz.shape, canz.sum(0).shape, fsc_state[n].shape)\n",
    "            #print(canz, canz.shape, canz.sum(1), (canz/canz.sum(1)[None, :]).sum(1), c_a)\n",
    "            #fsc_state[n] = canz/canz.sum(1)[:, None]\n",
    "\n",
    "            # NEW\n",
    "            fsc_action[n] = c_a\n",
    "            fsc_state[n] = canz/canz.sum(-1)[:, :, None]\n",
    "\n",
    "    V = pomdp.policy_evaluation_sr(fsc_action, fsc_state, T, O, R, gamma, dtype=dtype)\n",
    "    print(i, V, (prev-V).norm())\n",
    "    if (prev-V).norm() < 1e-3:\n",
    "        print('converged!')\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.5000, 0.5000],\n",
      "          [0.5002, 0.4998]],\n",
      "\n",
      "         [[0.5000, 0.5000],\n",
      "          [0.5003, 0.4997]]],\n",
      "\n",
      "\n",
      "        [[[0.5000, 0.5000],\n",
      "          [0.5002, 0.4998]],\n",
      "\n",
      "         [[0.5000, 0.5000],\n",
      "          [0.5003, 0.4997]]]])\n",
      "tensor([[[[0.5000, 0.5000],\n",
      "          [0.5000, 0.5000]],\n",
      "\n",
      "         [[0.5002, 0.4998],\n",
      "          [0.5003, 0.4997]]],\n",
      "\n",
      "\n",
      "        [[[0.5000, 0.5000],\n",
      "          [0.5000, 0.5000]],\n",
      "\n",
      "         [[0.5002, 0.4998],\n",
      "          [0.5003, 0.4997]]]])\n"
     ]
    }
   ],
   "source": [
    "hi = fsc_state.shape\n",
    "print(fsc_state.view(-1).repeat(2).view((2,)+hi))\n",
    "print(fsc_state.view(-1).repeat(2).view((2,)+hi).transpose(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.9204e-15, 1.0000e+00, 2.9368e-15, 1.0000e+00, 2.9204e-15, 1.0000e+00,\n",
       "        2.9368e-15, 1.0000e+00])"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsc_action.view(-1).repeat(2).view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
